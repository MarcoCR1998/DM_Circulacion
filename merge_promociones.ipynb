{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added `encoding='latin-1'` when loading csv files to prevent the following error:\n",
    "\n",
    "`UnicodeDecodeError: 'utf-8' codec can't decode byte 0xf3 in position 1147: invalid continuation byte`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load csv files\n",
    "hoja_1 = pd.read_csv('salida.csv', encoding='latin-1')\n",
    "hoja_2 = pd.read_csv('promociones.csv', encoding='latin-1')\n",
    "dias_festivos = pd.read_csv('dias_festivos_guatemala_2021_2025.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns to uniform data type\n",
    "hoja_1['fecha_edicion'] = pd.to_datetime(hoja_1['fecha_edicion'], format='%Y-%m-%d')\n",
    "\n",
    "hoja_2['fecha_inicio'] = pd.to_datetime(hoja_2['fecha_inicio'], format='%Y-%m-%d')\n",
    "hoja_2['fecha_fin'] = pd.to_datetime(hoja_2['fecha_fin'], format='%Y-%m-%d')\n",
    "\n",
    "dias_festivos['Fecha'] = pd.to_datetime(dias_festivos['Fecha'], format='%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique values for Tipo from hoja_2. These values will be used for\n",
    "# generating additional columns in the output file\n",
    "unique_tipo = list(set(hoja_2['Tipo']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique dates from hoja 1\n",
    "unique_dates = hoja_1['fecha_edicion'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building a helper dataframe to help out\n",
    "\n",
    "* First, a column of unique dates located in hoja_1\n",
    "* Second, a column for 'Feriados', where a 1 will be set if the uniqe date matches to a date in dias_festivos dataframe\n",
    "* Third, columns will be created for each item in unique_tipo, with values of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building helper data frame\n",
    "helper_df = pd.DataFrame(\n",
    "    {'date': unique_dates}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'Feriados' column to helper dataframe\n",
    "helper_df['Feriados'] = helper_df['date'].isin(dias_festivos['Fecha']).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column for each 'Tipo'\n",
    "for tipo in unique_tipo:\n",
    "    helper_df[tipo] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building another intermediate dataframe based on hoja_2 to make work easier\n",
    "\n",
    "* Group by 'Tipo'\n",
    "* Get lowest fecha_inicio and highest fecha_fin per contiguous time spans for 'Tipo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to collapse intervals. Given a list of intervals (tuple of start, end),\n",
    "# merge overlaping and adjacent intervals\n",
    "def collapse_intervals(intervals):\n",
    "    # Sort intervals by start date\n",
    "    intervals.sort(key=lambda x: x[0])\n",
    "    collapsed = []\n",
    "\n",
    "    for current_interval in intervals:\n",
    "        if not collapsed:\n",
    "            collapsed.append(list(current_interval))\n",
    "        else:\n",
    "            # Check if current interval starts within or right after the last merged interval\n",
    "            # If so, merge them.\n",
    "            if current_interval[0] <= collapsed[-1][1] + pd.Timedelta(days=1):\n",
    "                # Merge the intervals by extending the end date if necessaru\n",
    "                collapsed[-1][1] = max(collapsed[-1][1], current_interval[1])\n",
    "            else:\n",
    "                collapsed.append(list(current_interval))\n",
    "    \n",
    "    return collapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to merge intervals for each group of p_type\n",
    "def collapse_group(type_group):\n",
    "    # Get group name\n",
    "    group_name = type_group.name\n",
    "    # Create a list of (start_Data, end_date) tuples for the group\n",
    "    intervals = list(zip(type_group['fecha_inicio'], type_group['fecha_fin']))\n",
    "    collapsed = collapse_intervals(intervals)\n",
    "\n",
    "    collapsed_df = pd.DataFrame({\n",
    "        'Tipo': [group_name] * len(collapsed),\n",
    "        'fecha_inicio': [interval[0] for interval in collapsed],\n",
    "        'fecha_fin': [interval[1] for interval in collapsed]\n",
    "    })\n",
    "\n",
    "    return collapsed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hoja_2_collapsed = hoja_2.groupby('Tipo', group_keys=False)[['fecha_inicio', 'fecha_fin']].apply(collapse_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some magic:\n",
    "\n",
    "Now, for all the unique dates in helper_df, they will be checked to see if they fall in the range per 'Tipo' from the hoja_2_collapsed, and set a 1 in helper_df's corresponding column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in hoja_2_collapsed.iterrows():\n",
    "    tipo_h = row['Tipo']\n",
    "    start_date = row['fecha_inicio']\n",
    "    end_date = row['fecha_fin']\n",
    "\n",
    "    # Boolean mask to check if date is within range\n",
    "    in_range = (helper_df['date'] >= start_date) & (helper_df['date'] <= end_date)\n",
    "\n",
    "    # Set corresponding column to 1 where the condition is met\n",
    "    helper_df.loc[in_range, tipo_h] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The helper_df is complete. This df has for every unique date that appeared in hoja_1:\n",
    "* A column with the dates\n",
    "* A column for 'Feriados': set to 1 if it matches a date in the dias_festivos\n",
    "* Columns for each unique Tipo from hoja 2: with it's corresponding Tipo set to 1 if there is a match in the date ranges from hoja_2\n",
    "\n",
    "\n",
    "Now, the helper_df will be joined to hoja_1 to produce the expected outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-work: rename date column from helper_df to fecha edicion, in order to hava a cleaner result after merging\n",
    "helper_df = helper_df.rename(columns={'date': 'fecha_edicion'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the data\n",
    "hoja_1_enhanced = hoja_1.merge(helper_df, how='left', on='fecha_edicion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to output file\n",
    "hoja_1_enhanced.to_csv('hoja_1_enhanced.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
